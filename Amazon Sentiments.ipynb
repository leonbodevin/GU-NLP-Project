{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85016f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\18643\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\18643\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\18643\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\18643\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#All the imports\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf06adc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Record run time for code to decide on size of data set to use for analysis\n",
    "StartTime = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e22b992",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in two very different data frames: Luxury Beauty and Video Games\n",
    "#To help with intense computational requirements, limiting to approximately 100,000 reviews\n",
    "LuxuryBeautyDF = pd.read_json('Luxury_Beauty.json', lines=True) # Read in json file as a dataframe\n",
    "VideoGamesDF = pd.read_json('Video_Games_5.json', lines=True)\n",
    "Blend = [LuxuryBeautyDF,VideoGamesDF]\n",
    "BlendDF = pd.concat(Blend)\n",
    "BlendDF = BlendDF.sample(frac = 0.10).reset_index() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f300ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add column with Date from converted Unix time. Unfortunately results does not give time.\n",
    "BlendDF[\"Date\"] = pd.to_datetime(BlendDF[\"unixReviewTime\"], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e86c131",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create binary rating column: 0 (negative = 1-2), 1 (positive = 3-5)\n",
    "#Binning decision came from running tests against validation data\n",
    "conditions = [\n",
    "    (BlendDF[\"overall\"] > 2),\n",
    "    (BlendDF[\"overall\"] < 3)\n",
    "    ]\n",
    "values = [1, 0]\n",
    "BlendDF['BinaryRating'] = np.select(conditions, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06d5d39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create column of review text with all lowercase, no punctuation, and no stopwords\n",
    "nan_value = float(\"NaN\") #Create na variable for blanks\n",
    "BlendDF[\"reviewText\"].replace(\"\", nan_value, inplace=True) #Replace blanks with na variable\n",
    "BlendDF.dropna(subset = [\"reviewText\"], inplace=True) #Drop all rows with na review text\n",
    "BlendDF[\"ReviewNoFiller\"] = BlendDF[\"reviewText\"].str.replace('[^\\w\\s]','',regex=True) #Create column with review text with no punctuation\n",
    "BlendDF[\"ReviewNoFiller\"] = BlendDF[\"ReviewNoFiller\"].str.lower() #Make all words lowercase\n",
    "stopwords = stopwords.words('english') #Create stopwords variable\n",
    "BlendDF[\"ReviewNoFiller\"] = BlendDF[\"ReviewNoFiller\"].apply(lambda x: ' '.join([word for word in x.split() if word not in (stopwords)])) #Remove stop words\n",
    "BlendDF[\"ReviewNoFiller\"].replace(\"\", nan_value, inplace=True,regex=True) #Replace blanks with na\n",
    "BlendDF.dropna(subset = [\"ReviewNoFiller\"], inplace=True) #Drop all rows with na review text, reset indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5a326eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insert columns with tokenized review and summary\n",
    "BlendDF[\"ReviewToken\"] = BlendDF.apply(lambda row: word_tokenize(row[\"ReviewNoFiller\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d93aefb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lemmatize all reviews and summaries, rejoin the strings\n",
    "WNL = WordNetLemmatizer()\n",
    "def lemmatize_text(text):\n",
    "    return [WNL.lemmatize(w) for w in text]\n",
    "BlendDF['ReviewToken'] = BlendDF.ReviewToken.apply(lemmatize_text)\n",
    "BlendDF['ReviewLemma'] = BlendDF['ReviewToken'].apply(' '.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0731140f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5    68028\n",
      "4    16364\n",
      "3     9182\n",
      "1     8130\n",
      "2     5306\n",
      "Name: overall, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Print out distribution of resulting review ratings\n",
    "print(BlendDF['overall'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "987d03cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insert column with VADER sentiment analysis compound score of full review text, scale numbers from 1 to 5\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "BlendDF[\"VaderCompound\"] = [vader.polarity_scores(x)['compound'] for x in BlendDF[\"reviewText\"]]\n",
    "scaler = MinMaxScaler(feature_range=(1,5))\n",
    "BlendDF[\"VaderCompound\"] = scaler.fit_transform(BlendDF[\"VaderCompound\"].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a9adb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insert column with review word count\n",
    "BlendDF[\"WordCount\"] = BlendDF[\"ReviewToken\"].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78cfd107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    107010.000000\n",
      "mean         40.571246\n",
      "std          85.437565\n",
      "min           1.000000\n",
      "25%           6.000000\n",
      "50%          15.000000\n",
      "75%          37.000000\n",
      "max        2398.000000\n",
      "Name: WordCount, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#What does word count distribution look like? Need visualization to decide how to bin data. Also look at descriptive statistics.\n",
    "WordHist = BlendDF.hist(column = 'WordCount', bins=300)\n",
    "plt.xlim([0,150])\n",
    "print(BlendDF[\"WordCount\"].describe()) #25% is 6 or less, 25% is 29 words or more, will bin accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb48f5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create column categorizing review word count as short (1) or not (0)\n",
    "conditions = [\n",
    "    (BlendDF[\"WordCount\"] < 7),\n",
    "    (BlendDF[\"WordCount\"] > 6)\n",
    "    ]\n",
    "values = [1,0]\n",
    "BlendDF['Short'] = np.select(conditions, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31aa1461",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create column categorizing review word count as long (1) or not (0)\n",
    "conditions = [\n",
    "    (BlendDF[\"WordCount\"] > 28),\n",
    "    (BlendDF[\"WordCount\"] < 29)\n",
    "    ]\n",
    "values = [1,0]\n",
    "BlendDF['Long'] = np.select(conditions, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4fa7d1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create column categorizing reviewer as verified (1) or not (0)\n",
    "conditions = [\n",
    "    (BlendDF['verified'] == True),\n",
    "    (BlendDF['verified'] == False)\n",
    "    ]\n",
    "values = [1, 0]\n",
    "BlendDF['Verified'] = np.select(conditions, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a33de467",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create binary column if the reviewer uploaded an image (1) or did not (0)\n",
    "conditions = [\n",
    "    (pd.notnull(BlendDF['image'])),\n",
    "    (pd.isnull(BlendDF['image']))\n",
    "    ]\n",
    "values = [1, 0]\n",
    "BlendDF['IsImage'] = np.select(conditions, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a53b258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index                      int64\n",
      "overall                    int64\n",
      "vote                      object\n",
      "verified                    bool\n",
      "reviewTime                object\n",
      "reviewerID                object\n",
      "asin                      object\n",
      "reviewerName              object\n",
      "reviewText                object\n",
      "summary                   object\n",
      "unixReviewTime             int64\n",
      "style                     object\n",
      "image                     object\n",
      "Date              datetime64[ns]\n",
      "BinaryRating               int32\n",
      "ReviewNoFiller            object\n",
      "ReviewToken               object\n",
      "ReviewLemma               object\n",
      "VaderCompound            float64\n",
      "WordCount                  int64\n",
      "Short                      int32\n",
      "Long                       int32\n",
      "Verified                   int32\n",
      "IsImage                    int32\n",
      "dtype: object \n",
      "\n",
      "index                      int64\n",
      "overall                    int64\n",
      "vote                       int32\n",
      "verified                    bool\n",
      "reviewTime                object\n",
      "reviewerID                object\n",
      "asin                      object\n",
      "reviewerName              object\n",
      "reviewText                object\n",
      "summary                   object\n",
      "unixReviewTime             int64\n",
      "style                     object\n",
      "image                     object\n",
      "Date              datetime64[ns]\n",
      "BinaryRating               int32\n",
      "ReviewNoFiller            object\n",
      "ReviewToken               object\n",
      "ReviewLemma               object\n",
      "VaderCompound            float64\n",
      "WordCount                  int64\n",
      "Short                      int32\n",
      "Long                       int32\n",
      "Verified                   int32\n",
      "IsImage                    int32\n",
      "dtype: object \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Adjust vote column to allow for analysis\n",
    "print(BlendDF.dtypes,'\\n')\n",
    "BlendDF['vote'] = BlendDF['vote'].str.replace('[^\\w\\s]','',regex=True) #Remove all punctuation from strings\n",
    "BlendDF['vote'].replace('', '0', inplace=True) #Replace blanks with 0\n",
    "BlendDF['vote'] = BlendDF['vote'].fillna('0') # Replace na values with 0\n",
    "BlendDF['vote'] = BlendDF['vote'].astype({'vote': 'int32'})\n",
    "print(BlendDF.dtypes,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8dc3a57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read into five emotions lexicon, convert into five dictionaries\n",
    "WarrinerWords = pd.read_csv(\"Warriner_BE.txt\", sep='\\t')\n",
    "JoyDict = dict(zip(WarrinerWords.Word, WarrinerWords.Joy))\n",
    "AngerDict = dict(zip(WarrinerWords.Word, WarrinerWords.Anger))\n",
    "SadnessDict = dict(zip(WarrinerWords.Word, WarrinerWords.Sadness))\n",
    "FearDict = dict(zip(WarrinerWords.Word, WarrinerWords.Fear))\n",
    "DisgustDict = dict(zip(WarrinerWords.Word, WarrinerWords.Disgust))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a750a7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create columns for five emotions, initialize all of them at zero\n",
    "BlendDF['Joy'] = 0.0\n",
    "BlendDF['Anger'] = 0.0\n",
    "BlendDF['Sadness'] = 0.0\n",
    "BlendDF['Fear'] = 0.0\n",
    "BlendDF['Disgust'] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6354b54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterate through all lists of words, assigning them scores for all emotions\n",
    "for index, row in BlendDF.iterrows():\n",
    "    for word in row['ReviewToken']:\n",
    "        BlendDF.at[index,'Joy'] += JoyDict.get(word,0)\n",
    "        BlendDF.at[index,'Anger'] += AngerDict.get(word,0)\n",
    "        BlendDF.at[index,'Sadness'] += SadnessDict.get(word,0)\n",
    "        BlendDF.at[index,'Fear'] += FearDict.get(word,0)\n",
    "        BlendDF.at[index,'Disgust'] += DisgustDict.get(word,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d61dbe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReviewLemma\n",
      "VaderCompound\n",
      "Short\n",
      "Verified\n",
      "Long\n",
      "IsImage\n",
      "WordCount\n",
      "vote\n",
      "Joy\n",
      "Anger\n",
      "Sadness\n",
      "Fear\n",
      "Disgust\n",
      "overall\n",
      "BinaryRating\n",
      "                                         ReviewLemma  VaderCompound  Short  \\\n",
      "0  tried nba live 2004 cause updated roster jerse...       1.195620      0   \n",
      "1  loved balm amazing machine work first time rcv...       4.467547      0   \n",
      "2  become cliche ssx best launch title playstatio...       4.997600      0   \n",
      "3                                  pretty color pink       4.082108      1   \n",
      "4                             love brand mature skin       4.581158      1   \n",
      "\n",
      "   Verified  Long  IsImage  WordCount  vote       Joy       Anger     Sadness  \\\n",
      "0         0     1        0         75     0  102.0822   61.793200   57.913300   \n",
      "1         1     1        0         33     0   54.0334   28.069200   28.174300   \n",
      "2         0     1        0        434     0  648.5046  362.860801  349.611701   \n",
      "3         1     0        0          3     0   10.8865    3.748600    3.841300   \n",
      "4         1     0        0          4     0   10.3638    5.048200    5.119100   \n",
      "\n",
      "         Fear     Disgust  overall  BinaryRating  \n",
      "0   60.897100   66.952200        3             1  \n",
      "1   28.925900   28.026100        2             0  \n",
      "2  376.303399  350.609101        5             1  \n",
      "3    3.929200    3.567200        5             1  \n",
      "4    5.157300    4.905700        5             1  \n",
      "The number of rows in the data frame is: 107010\n"
     ]
    }
   ],
   "source": [
    "#Create data frame for analysis\n",
    "BlendDF = BlendDF[['ReviewLemma','VaderCompound','Short','Verified','Long','IsImage','WordCount','vote','Joy','Anger','Sadness','Fear','Disgust','overall','BinaryRating']]\n",
    "\n",
    "#Print some of the dataframe to verify work\n",
    "pd.set_option('display.max_columns', None) #So as not to truncate output\n",
    "pd.set_option('display.max_rows', None) #So as not to truncate output\n",
    "for col in BlendDF.columns: #Print column names\n",
    "    print(col)\n",
    "print(BlendDF.head()) # Print first five entries in dataframe\n",
    "print(\"The number of rows in the data frame is:\", len(BlendDF.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38316796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write final dataframe into csv\n",
    "BlendDF.to_csv(r'BlendedReviews.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9b90375b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Linear SVC Model Score for TFIDF is: 89.5 % \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.63      0.60      2717\n",
      "           1       0.95      0.93      0.94     18685\n",
      "\n",
      "    accuracy                           0.89     21402\n",
      "   macro avg       0.76      0.78      0.77     21402\n",
      "weighted avg       0.90      0.89      0.90     21402\n",
      " \n",
      "\n",
      "Multiclass Linear SVC Model Score for TFIDF is: 64.63 % \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.52      0.52      1669\n",
      "           2       0.22      0.21      0.21      1048\n",
      "           3       0.28      0.30      0.29      1811\n",
      "           4       0.32      0.34      0.33      3208\n",
      "           5       0.83      0.81      0.82     13666\n",
      "\n",
      "    accuracy                           0.65     21402\n",
      "   macro avg       0.43      0.44      0.44     21402\n",
      "weighted avg       0.65      0.65      0.65     21402\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "TF-IDF Approach\n",
    "\"\"\"\n",
    "\n",
    "#Implement TF-IDF for binary model\n",
    "tfidf = TfidfVectorizer(max_features=100000, ngram_range=(1,5), analyzer='char')\n",
    "X = tfidf.fit_transform(BlendDF['ReviewLemma'])\n",
    "Y = BlendDF['BinaryRating']\n",
    "X.shape, Y.shape\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1) #Split into 80/20 train and test sets\n",
    "\n",
    "#Implement Linear SVC model for binary TF-IDF\n",
    "#89.55% Accuracy for 10% of data, 89.09% for 25% of data\n",
    "LSVC = LinearSVC(C = 10, class_weight='balanced', max_iter=10000)\n",
    "LSVC.fit(X_train, Y_train)\n",
    "LSVCScore = round((LSVC.score(X_test, Y_test))*100,2)\n",
    "print('Binary Linear SVC Model Score for TFIDF is:',LSVCScore,'%', '\\n')\n",
    "Y_pred = LSVC.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred, zero_division=0), '\\n')\n",
    "\n",
    "#Implement TF-IDF for multiclass model\n",
    "tfidf = TfidfVectorizer(max_features=100000, ngram_range=(1,5), analyzer='char')\n",
    "X = tfidf.fit_transform(BlendDF['ReviewLemma'])\n",
    "Y = BlendDF['overall']\n",
    "X.shape, Y.shape\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1) #Split into 80/20 train and test sets\n",
    "\n",
    "#Implement Linear SVC model for TF-IDF multiclass\n",
    "#63.98% Accuracy for 10% of data, 64.98% for 25% of data\n",
    "LSVC = LinearSVC(C = 10, class_weight='balanced', max_iter=10000)\n",
    "LSVC.fit(X_train, Y_train)\n",
    "LSVCScore = round((LSVC.score(X_test, Y_test))*100,2)\n",
    "print('Multiclass Linear SVC Model Score for TFIDF is:',LSVCScore,'%', '\\n')\n",
    "Y_pred = LSVC.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred, zero_division=0), '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "36fb7069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Logistic Intercept is: [-2.25204214] \n",
      "\n",
      "Binary Logistic Coefficients are: [[ 1.04747842  0.68953168  0.22340488 -0.10213282 -0.71526729]] \n",
      "\n",
      "Binary Logistic Model Score for VADER Score and other variables: 87.45 % \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.23      0.32      2717\n",
      "           1       0.90      0.97      0.93     18685\n",
      "\n",
      "    accuracy                           0.87     21402\n",
      "   macro avg       0.70      0.60      0.62     21402\n",
      "weighted avg       0.85      0.87      0.85     21402\n",
      " \n",
      "\n",
      "Binary SVM Score for VADER Score and other variables: 87.3 % \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      2717\n",
      "           1       0.87      1.00      0.93     18685\n",
      "\n",
      "    accuracy                           0.87     21402\n",
      "   macro avg       0.44      0.50      0.47     21402\n",
      "weighted avg       0.76      0.87      0.81     21402\n",
      " \n",
      "\n",
      "Binary Naive Bayes Classifier Score for VADER Score and other variables: 87.1 % \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.32      0.38      2717\n",
      "           1       0.91      0.95      0.93     18685\n",
      "\n",
      "    accuracy                           0.87     21402\n",
      "   macro avg       0.70      0.63      0.66     21402\n",
      "weighted avg       0.85      0.87      0.86     21402\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "VADER Score and other variables approach\n",
    "First group of models are binary models predicting positive or negative rating\n",
    "\"\"\"\n",
    "\n",
    "#Split data into training and test sets with a 80/20 split for all binary models\n",
    "#Based on the very low coefficients for both WordCount and vote, these variables were left out of the models.\n",
    "X = BlendDF[['VaderCompound','Short','Verified','Long','IsImage']] #set independent variables for regression\n",
    "Y = BlendDF['BinaryRating'] #set dependent variable for regression\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1) #Split into 80/20 train and test sets\n",
    "\n",
    "#Run binary logistic regression\n",
    "LR = linear_model.LogisticRegression()\n",
    "LR.fit(X_train, Y_train)\n",
    "print('Binary Logistic Intercept is:', LR.intercept_, '\\n')\n",
    "print('Binary Logistic Coefficients are:', LR.coef_, '\\n')\n",
    "\n",
    "#Look at ability of model to predict test set\n",
    "#87.97% Accuracy for 10% of data, 88.14% for 25% of data\n",
    "LRScore = round((LR.score(X_test, Y_test))*100,2)\n",
    "print('Binary Logistic Model Score for VADER Score and other variables:',LRScore,'%','\\n')\n",
    "Y_pred = LR.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred, zero_division=0), '\\n')\n",
    "\n",
    "#Run Binary SVM\n",
    "svclassifier = SVC(kernel='linear')\n",
    "svclassifier.fit(X_train, Y_train)\n",
    "\n",
    "#Look at ability of model to predict test set\n",
    "#87.67% Accuracy for 10% of data, 87.6% for 25% of data\n",
    "SVMScore = round((svclassifier.score(X_test, Y_test))*100,2)\n",
    "print('Binary SVM Score for VADER Score and other variables:',SVMScore,'%','\\n')\n",
    "Y_pred = svclassifier.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred, zero_division=0), '\\n')\n",
    "\n",
    "#Run Naive Bayes Classifier\n",
    "NB = GaussianNB()\n",
    "NB.fit(X_train, Y_train)\n",
    "\n",
    "#Look at ability of model to predict test set\n",
    "#87.28% Accuracy with 10% of data, 87.54% with 25% of data\n",
    "NBScore = round((NB.score(X_test, Y_test))*100,2)\n",
    "print('Binary Naive Bayes Classifier Score for VADER Score and other variables:',NBScore,'%','\\n')\n",
    "Y_pred = NB.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred, zero_division=0), '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a4e44ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Logistic Model Score for VADER Score and other variables:  65.2 % \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.37      0.36      1669\n",
      "           2       0.00      0.00      0.00      1048\n",
      "           3       0.14      0.01      0.02      1811\n",
      "           4       0.22      0.00      0.01      3208\n",
      "           5       0.68      0.97      0.80     13666\n",
      "\n",
      "    accuracy                           0.65     21402\n",
      "   macro avg       0.28      0.27      0.24     21402\n",
      "weighted avg       0.51      0.65      0.54     21402\n",
      " \n",
      "\n",
      "Multiclass SVM Score is for VADER Score and other variables:  65.26 % \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.37      0.35      0.36      1669\n",
      "           2       0.00      0.00      0.00      1048\n",
      "           3       0.00      0.00      0.00      1811\n",
      "           4       0.00      0.00      0.00      3208\n",
      "           5       0.68      0.98      0.80     13666\n",
      "\n",
      "    accuracy                           0.65     21402\n",
      "   macro avg       0.21      0.27      0.23     21402\n",
      "weighted avg       0.46      0.65      0.54     21402\n",
      " \n",
      "\n",
      "K Nearest Neighbors Algorithm Model Score for VADER Score and other variables:  63.91 % \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.37      0.37      0.37      1669\n",
      "           2       0.16      0.03      0.06      1048\n",
      "           3       0.22      0.07      0.11      1811\n",
      "           4       0.24      0.07      0.11      3208\n",
      "           5       0.71      0.93      0.80     13666\n",
      "\n",
      "    accuracy                           0.64     21402\n",
      "   macro avg       0.34      0.30      0.29     21402\n",
      "weighted avg       0.54      0.64      0.57     21402\n",
      " \n",
      "\n",
      "Random Forest Classifier Model Score for VADER Score and other variables:  61.04 % \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      0.28      0.31      1669\n",
      "           2       0.12      0.08      0.10      1048\n",
      "           3       0.17      0.10      0.12      1811\n",
      "           4       0.22      0.11      0.15      3208\n",
      "           5       0.71      0.88      0.79     13666\n",
      "\n",
      "    accuracy                           0.61     21402\n",
      "   macro avg       0.32      0.29      0.29     21402\n",
      "weighted avg       0.54      0.61      0.56     21402\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "VADER Score and other variables approach\n",
    "Second group of models are multiclass models for 1-5 rating\n",
    "\"\"\"\n",
    "#Split data into training and test sets with a 80/20 split for multiclass models\n",
    "X = BlendDF[['VaderCompound','Short','Verified','Long','IsImage']] #set independent variables for regression\n",
    "Y = BlendDF['overall'] #set dependent variable for regression\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1) #Split into 80/20 train and test sets\n",
    "\n",
    "#Run multinomial logistic regression\n",
    "MLR = linear_model.LogisticRegression(multi_class='multinomial', solver='lbfgs',max_iter=10000)\n",
    "MLR.fit(X_train, Y_train)\n",
    "\n",
    "#Look at ability of model to predict test set\n",
    "#64.86% Accuracy with 10% of data, 65.04% with 25% of data\n",
    "MLRScore = round((MLR.score(X_test, Y_test))*100,2)\n",
    "print('Multinomial Logistic Model Score for VADER Score and other variables: ',MLRScore,'%','\\n')\n",
    "Y_pred = MLR.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred, zero_division=0), '\\n')\n",
    "\n",
    "#Run Multiclass SVM\n",
    "msvclassifier = SVC(kernel='linear')\n",
    "msvclassifier.fit(X_train, Y_train)\n",
    "\n",
    "#Look at ability of model to predict test set\n",
    "#64.79% Accuracy with 10% of data, 64.97% with 25% of data\n",
    "MSVMScore = round((msvclassifier.score(X_test, Y_test))*100,2)\n",
    "print('Multiclass SVM Score is for VADER Score and other variables: ',MSVMScore,'%','\\n')\n",
    "Y_pred = msvclassifier.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred, zero_division=0), '\\n')\n",
    "\n",
    "#Run K Nearest Neighbors Algorithm\n",
    "KNN = KNeighborsClassifier(n_neighbors = 15)\n",
    "KNN.fit(X_train, Y_train)\n",
    "\n",
    "#Look at ability of model to predict test set\n",
    "#63.37% Accuracy with 10% of data, 63.23% with 25% of data\n",
    "KNNScore = round((KNN.score(X_test, Y_test))*100,2)\n",
    "print('K Nearest Neighbors Algorithm Model Score for VADER Score and other variables: ',KNNScore,'%','\\n')\n",
    "Y_pred = KNN.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred, zero_division=0), '\\n')\n",
    "\n",
    "#Run Random Forest Algorithm\n",
    "RF = RandomForestClassifier(n_estimators=5, random_state=0)\n",
    "RF.fit(X_train, Y_train)\n",
    "\n",
    "#Look at ability of model to predict test set\n",
    "#60.43% Accuracy with 10% of data, 62.73% with 25% of data\n",
    "RFScore = round((RF.score(X_test, Y_test))*100,2)\n",
    "print('Random Forest Classifier Model Score for VADER Score and other variables: ',RFScore,'%','\\n')\n",
    "Y_pred = RF.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred, zero_division=0), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "30d94258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Classifier Score is for Five Emotions Model:  87.3 % \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      2717\n",
      "           1       0.87      1.00      0.93     18685\n",
      "\n",
      "    accuracy                           0.87     21402\n",
      "   macro avg       0.44      0.50      0.47     21402\n",
      "weighted avg       0.76      0.87      0.81     21402\n",
      " \n",
      "\n",
      "Binary Logistic Model Score for Five Emotions Model:  87.04 % \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.02      0.04      2717\n",
      "           1       0.87      0.99      0.93     18685\n",
      "\n",
      "    accuracy                           0.87     21402\n",
      "   macro avg       0.60      0.51      0.48     21402\n",
      "weighted avg       0.80      0.87      0.82     21402\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Five Emotions Approach\n",
    "First group of models are binary models predicting positive or negative rating\n",
    "SVM Models have been excluded due to high number of continuous variables makes processing power/time overwhelming\n",
    "\"\"\"\n",
    "\n",
    "#Split data into training and test sets with a 80/20 split for all binary models\n",
    "#Based on the very low coefficients for both WordCount and vote, these variables were left out of the models.\n",
    "X = BlendDF[['Joy','Anger','Sadness','Fear','Disgust']] #set independent variables for regression\n",
    "Y = BlendDF['BinaryRating'] #set dependent variable for regression\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1) #Split into 80/20 train and test sets\n",
    "\n",
    "#Run Naive Bayes Classifier\n",
    "NB = GaussianNB()\n",
    "NB.fit(X_train, Y_train)\n",
    "\n",
    "#Look at ability of model to predict test set\n",
    "#87.67% Accuracy with 10% of data, 87.6% with 25% of data\n",
    "NBScore = round((NB.score(X_test, Y_test))*100,2)\n",
    "print('Naive Bayes Classifier Score is for Five Emotions Model: ',NBScore,'%','\\n')\n",
    "Y_pred = NB.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred, zero_division=0), '\\n')\n",
    "\n",
    "#Run binary logistic regression\n",
    "LR = linear_model.LogisticRegression()\n",
    "LR.fit(X_train, Y_train)\n",
    "\n",
    "#Look at ability of model to predict test set\n",
    "#87.45 % Accuracy with 10% of data, 87.38% with 25% of data\n",
    "LRScore = round((LR.score(X_test, Y_test))*100,2)\n",
    "print('Binary Logistic Model Score for Five Emotions Model: ',LRScore,'%','\\n')\n",
    "Y_pred = LR.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred, zero_division=0), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b3b86c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Logistic Model Score for Five Emotions Model:  63.98 % \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.28      0.04      0.07      1669\n",
      "           2       0.09      0.00      0.00      1048\n",
      "           3       0.23      0.01      0.01      1811\n",
      "           4       0.40      0.03      0.06      3208\n",
      "           5       0.65      0.99      0.78     13666\n",
      "\n",
      "    accuracy                           0.64     21402\n",
      "   macro avg       0.33      0.21      0.19     21402\n",
      "weighted avg       0.52      0.64      0.52     21402\n",
      " \n",
      "\n",
      "K Nearest Neighbors Algorithm Model Score for Five Emotions Model:  62.47 % \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.31      0.15      0.20      1669\n",
      "           2       0.10      0.01      0.02      1048\n",
      "           3       0.13      0.02      0.04      1811\n",
      "           4       0.26      0.08      0.13      3208\n",
      "           5       0.67      0.94      0.78     13666\n",
      "\n",
      "    accuracy                           0.62     21402\n",
      "   macro avg       0.29      0.24      0.23     21402\n",
      "weighted avg       0.51      0.62      0.54     21402\n",
      " \n",
      "\n",
      "Random Forest Classifier Model Score for Five Emotions Model:  54.99 % \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.23      0.22      0.22      1669\n",
      "           2       0.09      0.07      0.08      1048\n",
      "           3       0.15      0.11      0.13      1811\n",
      "           4       0.22      0.17      0.19      3208\n",
      "           5       0.70      0.77      0.74     13666\n",
      "\n",
      "    accuracy                           0.55     21402\n",
      "   macro avg       0.28      0.27      0.27     21402\n",
      "weighted avg       0.52      0.55      0.53     21402\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Five Emotions Approach\n",
    "Second group of models are multiclass models for 1-5 rating\n",
    "SVM Models have been excluded due to high number of continuous variables makes processing power/time overwhelming\n",
    "\"\"\"\n",
    "\n",
    "#Split data into training and test sets with a 80/20 split for multiclass models\n",
    "X = BlendDF[['Joy','Anger','Sadness','Fear','Disgust']] #set independent variables for regression\n",
    "Y = BlendDF['overall'] #set dependent variable for regression\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1) #Split into 80/20 train and test sets\n",
    "\n",
    "#Run multinomial logistic regression\n",
    "MLR = linear_model.LogisticRegression(multi_class='multinomial', solver='lbfgs',max_iter=10000)\n",
    "MLR.fit(X_train, Y_train)\n",
    "\n",
    "#Look at ability of model to predict test set\n",
    "#63.62% Accuracy with 10% of data, 63.56% with 25% of data\n",
    "MLRScore = round((MLR.score(X_test, Y_test))*100,2)\n",
    "print('Multinomial Logistic Model Score for Five Emotions Model: ',MLRScore,'%','\\n')\n",
    "Y_pred = MLR.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred, zero_division=0), '\\n')\n",
    "\n",
    "#Run K Nearest Neighbors Algorithm\n",
    "KNN = KNeighborsClassifier(n_neighbors = 15)\n",
    "KNN.fit(X_train, Y_train)\n",
    "\n",
    "#Look at ability of model to predict test set\n",
    "#62.55% Accuracy with 10% of data, 62.21% with 25% of data\n",
    "KNNScore = round((KNN.score(X_test, Y_test))*100,2)\n",
    "print('K Nearest Neighbors Algorithm Model Score for Five Emotions Model: ',KNNScore,'%','\\n')\n",
    "Y_pred = KNN.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred, zero_division=0), '\\n')\n",
    "\n",
    "#Run Random Forest Algorithm\n",
    "RF = RandomForestClassifier(n_estimators=5, random_state=0)\n",
    "RF.fit(X_train, Y_train)\n",
    "\n",
    "#Look at ability of model to predict test set\n",
    "#55.39% Accuracy with 10% of data, 56.14% with 25% of data\n",
    "RFScore = round((RF.score(X_test, Y_test))*100,2)\n",
    "print('Random Forest Classifier Model Score for Five Emotions Model: ',RFScore,'%','\\n')\n",
    "Y_pred = RF.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred, zero_division=0), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "62a03bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:32:18\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Print out run times to decide how big of a data set to use\n",
    "Code run times: 25 minutes 13 seconds for 10% of data; 2 hours 58 minutes 5 seconds for 25% of data\n",
    "\"\"\"\n",
    "\n",
    "ElapsedSeconds = time.time() - StartTime\n",
    "def convert(seconds):\n",
    "    seconds = seconds % (24 * 3600)\n",
    "    hour = seconds // 3600\n",
    "    seconds %= 3600\n",
    "    minutes = seconds // 60\n",
    "    seconds %= 60\n",
    "\n",
    "    return \"%d:%02d:%02d\" % (hour, minutes, seconds)\n",
    "print(convert(ElapsedSeconds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
